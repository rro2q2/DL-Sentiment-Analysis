{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install torchtext\n",
    "# !pip install transformers\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 800\n",
      "Number of validation examples: 200\n",
      "Number of testing examples: 200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Using the BERT model for tokenizing.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize words and cut sentences exceeding the max length.\n",
    "def tokenize_and_cut(sentence):\n",
    "    max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens\n",
    "\n",
    "test_field = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "\n",
    "label_field = data.LabelField(dtype = torch.float)\n",
    "\n",
    "# Loading the training dataset.\n",
    "train_dataset = data.TabularDataset(\n",
    "path='../data/Proble4Dataset_large_train.csv', format='csv', skip_header=True,\n",
    "fields=[('text', test_field),\n",
    "        ('label', label_field)])\n",
    "\n",
    "# Loading the testing dataset.\n",
    "test_data = data.TabularDataset(\n",
    "path='../data/Proble4Dataset_large_test.csv', format='csv', skip_header=True,\n",
    "fields=[('text', test_field),\n",
    "        ('label', label_field)])\n",
    "\n",
    "# Splitting the training data into 80% train and 20% validation sets.\n",
    "train_data, valid_data = train_dataset.split(split_ratio=0.8)\n",
    "\n",
    "# Building the vocabulary for the labels\n",
    "label_field.build_vocab(train_data)\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the batch size.\n",
    "batch_size = 5\n",
    "\n",
    "# Iterators for the training, validation and test sets.\n",
    "train_iterator = data.BucketIterator(train_data, batch_size = batch_size, device = device)\n",
    "valid_iterator = data.BucketIterator(valid_data, batch_size = batch_size, device = device)\n",
    "test_iterator = data.BucketIterator(test_data, batch_size = batch_size, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [SEP] [PAD] [UNK]\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 112,241,409 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,759,169 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.764 | Train Acc: 52.88%\n",
      "\t Val. Loss: 0.640 |  Val. Acc: 67.50%\n",
      "Epoch: 02 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.632 | Train Acc: 65.38%\n",
      "\t Val. Loss: 0.639 |  Val. Acc: 64.50%\n",
      "Epoch: 03 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.570 | Train Acc: 71.00%\n",
      "\t Val. Loss: 0.648 |  Val. Acc: 60.50%\n",
      "Epoch: 04 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.518 | Train Acc: 75.50%\n",
      "\t Val. Loss: 0.675 |  Val. Acc: 69.50%\n",
      "Epoch: 05 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.458 | Train Acc: 77.50%\n",
      "\t Val. Loss: 0.685 |  Val. Acc: 67.00%\n",
      "Epoch: 06 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.386 | Train Acc: 83.38%\n",
      "\t Val. Loss: 0.710 |  Val. Acc: 69.00%\n",
      "Epoch: 07 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.293 | Train Acc: 86.88%\n",
      "\t Val. Loss: 0.838 |  Val. Acc: 64.50%\n",
      "Epoch: 08 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.203 | Train Acc: 92.38%\n",
      "\t Val. Loss: 0.919 |  Val. Acc: 67.50%\n",
      "Epoch: 09 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.156 | Train Acc: 93.25%\n",
      "\t Val. Loss: 1.120 |  Val. Acc: 63.00%\n",
      "Epoch: 10 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.167 | Train Acc: 93.38%\n",
      "\t Val. Loss: 1.011 |  Val. Acc: 69.50%\n",
      "Epoch: 11 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.100 | Train Acc: 95.63%\n",
      "\t Val. Loss: 1.118 |  Val. Acc: 67.50%\n",
      "Epoch: 12 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.099 | Train Acc: 96.88%\n",
      "\t Val. Loss: 1.510 |  Val. Acc: 55.50%\n",
      "Epoch: 13 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.063 | Train Acc: 97.50%\n",
      "\t Val. Loss: 1.315 |  Val. Acc: 69.00%\n",
      "Epoch: 14 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.031 | Train Acc: 99.13%\n",
      "\t Val. Loss: 1.569 |  Val. Acc: 66.50%\n",
      "Epoch: 15 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.033 | Train Acc: 98.88%\n",
      "\t Val. Loss: 1.379 |  Val. Acc: 69.00%\n",
      "Epoch: 16 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.054 | Train Acc: 98.25%\n",
      "\t Val. Loss: 1.452 |  Val. Acc: 69.00%\n",
      "Epoch: 17 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.061 | Train Acc: 97.50%\n",
      "\t Val. Loss: 1.682 |  Val. Acc: 66.00%\n",
      "Epoch: 18 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.041 | Train Acc: 98.50%\n",
      "\t Val. Loss: 1.594 |  Val. Acc: 67.50%\n",
      "Epoch: 19 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.067 | Train Acc: 97.50%\n",
      "\t Val. Loss: 1.485 |  Val. Acc: 69.00%\n",
      "Epoch: 20 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.041 | Train Acc: 98.38%\n",
      "\t Val. Loss: 1.507 |  Val. Acc: 67.00%\n",
      "Training Time ::  142.73305487632751\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses_lst = []\n",
    "valid_losses_lst = []\n",
    "\n",
    "# Auditing the start time.\n",
    "start_time_total = time.time()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'bert-large-model.pt')\n",
    "    \n",
    "    train_losses_lst.append(train_loss)\n",
    "    valid_losses_lst.append(valid_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "# Auditing the start time.\n",
    "time_taken_total = time.time() - start_time_total\n",
    "print(\"Training Time :: \", time_taken_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.688 | Test Acc: 58.50%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('bert-large-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the learning curves.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses_lst, 'r', label=\"Training Loss\")\n",
    "plt.plot(valid_losses_lst, 'g', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('BERT-Large.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "        \n",
    "    # Converting the output into a predicted class (0 or 1).\n",
    "    prediction = torch.round(prediction.squeeze())\n",
    "    \n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This is a word!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>#um# I mean, I don't know if I'll be around bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Oh, it went fine. Yeah, no problem, I mean it'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>#uh# we take em' to #uh# it's not well it's fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Right, okay, and I have been working with #uhh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Yeah 'Wen_Wednesday' would work better for me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Label\n",
       "915  #um# I mean, I don't know if I'll be around bu...      0\n",
       "600  Oh, it went fine. Yeah, no problem, I mean it'...      0\n",
       "527  #uh# we take em' to #uh# it's not well it's fr...      0\n",
       "433  Right, okay, and I have been working with #uhh...      1\n",
       "409  Yeah 'Wen_Wednesday' would work better for me ...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the training dataset.\n",
    "train_data_input = pd.read_csv(\"../data/Proble4Dataset_large_train.csv\")\n",
    "train_data_input = train_data_input.reindex(np.random.permutation(train_data_input.index)) # Shuffling the data.\n",
    "\n",
    "# Loading the testing dataset.\n",
    "test_data_input = pd.read_csv(\"../data/Proble4Dataset_large_test.csv\")\n",
    "\n",
    "# Sample text and its label.\n",
    "train_data_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function for getting the confusion matrix.\n",
    "def confusion(prediction, truth):\n",
    "    confusion_vector = prediction / truth\n",
    "    \n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ::  0.734\n",
      "Confusion Matrix :: \n",
      " 352 \t 118 \n",
      " 148 \t 382\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the confusion matrix for the training dataset.\n",
    "prediction_lst = []\n",
    "for text, label in zip(train_data_input[\"Text\"], train_data_input[\"Label\"]):\n",
    "    prediction_lst.append(predict_sentiment(model, text))\n",
    "    \n",
    "true_positives, false_positives, true_negatives, false_negatives = confusion(\n",
    "    torch.Tensor(prediction_lst), torch.tensor(train_data_input[\"Label\"].to_numpy()))\n",
    "\n",
    "accuracy = (true_positives + true_negatives)/len(prediction_lst)\n",
    "print(\"Accuracy :: \", accuracy)\n",
    "print(\"Confusion Matrix :: \\n\", true_positives, \"\\t\", false_positives, \"\\n\", false_negatives, \"\\t\", true_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ::  0.6\n",
      "Confusion Matrix :: \n",
      " 54 \t 34 \n",
      " 46 \t 66\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the confusion matrix for the testing dataset.\n",
    "prediction_lst = []\n",
    "for text, label in zip(test_data_input[\"Text\"], test_data_input[\"Label\"]):\n",
    "    prediction_lst.append(predict_sentiment(model, text))\n",
    "\n",
    "true_positives, false_positives, true_negatives, false_negatives = confusion(\n",
    "    torch.Tensor(prediction_lst), torch.Tensor(test_data_input[\"Label\"].to_numpy()))\n",
    "accuracy = (true_positives + true_negatives)/len(prediction_lst)\n",
    "\n",
    "print(\"Accuracy :: \", accuracy)\n",
    "print(\"Confusion Matrix :: \\n\", true_positives, \"\\t\", false_positives, \"\\n\", false_negatives, \"\\t\", true_negatives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

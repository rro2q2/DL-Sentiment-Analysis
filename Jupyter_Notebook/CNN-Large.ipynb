{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f1d22dafc88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 800\n",
      "Number of validation examples: 200\n",
      "Number of testing examples: 200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "text_field = data.Field(tokenize = 'spacy', batch_first = True)\n",
    "\n",
    "label_field = data.LabelField(dtype = torch.float)\n",
    "\n",
    "# Loading the training dataset.\n",
    "train_dataset = data.TabularDataset(\n",
    "path='../data/Proble4Dataset_large_train.csv', format='csv', skip_header=True,\n",
    "fields=[('text', text_field),\n",
    "        ('label', label_field)])\n",
    "\n",
    "# Loading the testing dataset.\n",
    "test_data = data.TabularDataset(\n",
    "path='../data/Proble4Dataset_large_test.csv', format='csv', skip_header=True,\n",
    "fields=[('text', text_field),\n",
    "        ('label', label_field)])\n",
    "\n",
    "# Splitting the training data into 80% train and 20% validation sets.\n",
    "train_data, valid_data = train_dataset.split(split_ratio=0.8)\n",
    "\n",
    "# Building the vocabulary for the labels\n",
    "label_field.build_vocab(train_data)\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the batch size.\n",
    "batch_size = 64\n",
    "\n",
    "# Iterators for the training, validation and test sets.\n",
    "train_iterator = data.BucketIterator(train_data, batch_size = batch_size)\n",
    "valid_iterator = data.BucketIterator(valid_data, batch_size = batch_size)\n",
    "test_iterator = data.BucketIterator(test_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[0], embedding_dim))\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[1], embedding_dim))\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "text_field.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(text_field.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = text_field.vocab.stoi[text_field.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 391,901 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6968,  0.4247, -0.2626,  ..., -0.8779,  0.3244,  1.5239],\n",
       "        [-0.1339,  0.6427,  0.4227,  ...,  1.2142,  1.7557, -0.5392],\n",
       "        [-0.6610, -0.0730,  0.9238,  ..., -0.2256,  0.8148, -0.4405],\n",
       "        ...,\n",
       "        [-0.2195,  1.7290, -0.6388,  ..., -0.9335, -0.0113, -1.2845],\n",
       "        [-0.1979, -0.4355, -0.4311,  ..., -1.0606, -0.1969,  1.8724],\n",
       "        [-0.2871, -0.6629, -1.2582,  ...,  0.6277, -0.7085, -0.2229]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = text_field.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = text_field.vocab.stoi[text_field.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.697 | Train Acc: 55.89%\n",
      "\t Val. Loss: 0.670 |  Val. Acc: 64.84%\n",
      "Epoch: 02 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.632 | Train Acc: 64.42%\n",
      "\t Val. Loss: 0.690 |  Val. Acc: 53.12%\n",
      "Epoch: 03 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.575 | Train Acc: 73.20%\n",
      "\t Val. Loss: 0.668 |  Val. Acc: 58.98%\n",
      "Epoch: 04 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.531 | Train Acc: 79.09%\n",
      "\t Val. Loss: 0.658 |  Val. Acc: 58.59%\n",
      "Epoch: 05 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.487 | Train Acc: 79.81%\n",
      "\t Val. Loss: 0.616 |  Val. Acc: 62.11%\n",
      "Epoch: 06 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.443 | Train Acc: 83.17%\n",
      "\t Val. Loss: 0.583 |  Val. Acc: 66.02%\n",
      "Epoch: 07 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.403 | Train Acc: 87.14%\n",
      "\t Val. Loss: 0.597 |  Val. Acc: 68.36%\n",
      "Epoch: 08 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.351 | Train Acc: 90.99%\n",
      "\t Val. Loss: 0.657 |  Val. Acc: 62.50%\n",
      "Epoch: 09 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.312 | Train Acc: 91.23%\n",
      "\t Val. Loss: 0.541 |  Val. Acc: 70.31%\n",
      "Epoch: 10 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 0.280 | Train Acc: 93.75%\n",
      "\t Val. Loss: 0.598 |  Val. Acc: 64.84%\n",
      "Training Time ::  2.3262951374053955\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses_lst = []\n",
    "valid_losses_lst = []\n",
    "\n",
    "# Auditing the start time.\n",
    "start_time_total = time.time()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'cnn-model-large.pt')\n",
    "        \n",
    "    train_losses_lst.append(train_loss)\n",
    "    valid_losses_lst.append(valid_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "# Auditing the start time.\n",
    "time_taken_total = time.time() - start_time_total\n",
    "print(\"Training Time :: \", time_taken_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.707 | Test Acc: 49.61%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('cnn-model-large.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the learning curves.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses_lst, 'r', label=\"Training Loss\")\n",
    "plt.plot(valid_losses_lst, 'g', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('CNN-Large.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence, min_len = 5):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [text_field.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    \n",
    "    # Converting the output into a predicted class (0 or 1).\n",
    "    prediction = torch.round(prediction.squeeze())\n",
    "    \n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This is a word!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Right, get set, supreme equipment transport #h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>You know the only trucks we have are just smal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>We do not want we are not going to buy anythin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>We may need #uh# not a a not per say a truck, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Okay #um# yeah, I'll love to sit down and talk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Label\n",
       "68   Right, get set, supreme equipment transport #h...      1\n",
       "840  You know the only trucks we have are just smal...      0\n",
       "120  We do not want we are not going to buy anythin...      1\n",
       "706  We may need #uh# not a a not per say a truck, ...      0\n",
       "24   Okay #um# yeah, I'll love to sit down and talk...      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the training dataset.\n",
    "train_data_input = pd.read_csv(\"../data/Proble4Dataset_large_train.csv\")\n",
    "train_data_input = train_data_input.reindex(np.random.permutation(train_data_input.index)) # Shuffling the data.\n",
    "\n",
    "# Loading the testing dataset.\n",
    "test_data_input = pd.read_csv(\"../data/Proble4Dataset_large_test.csv\")\n",
    "\n",
    "# Sample text and its label.\n",
    "train_data_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function for getting the confusion matrix.\n",
    "def confusion(prediction, truth):\n",
    "    confusion_vector = prediction / truth\n",
    "    \n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ::  0.88\n",
      "Confusion Matrix :: \n",
      " 419 \t 39 \n",
      " 81 \t 461\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the confusion matrix for the training dataset.\n",
    "prediction_lst = []\n",
    "for text, label in zip(train_data_input[\"Text\"], train_data_input[\"Label\"]):\n",
    "    prediction_lst.append(predict_sentiment(model, text))\n",
    "    \n",
    "true_positives, false_positives, true_negatives, false_negatives = confusion(\n",
    "    torch.Tensor(prediction_lst), torch.tensor(train_data_input[\"Label\"].to_numpy()))\n",
    "\n",
    "accuracy = (true_positives + true_negatives)/len(prediction_lst)\n",
    "print(\"Accuracy :: \", accuracy)\n",
    "print(\"Confusion Matrix :: \\n\", true_positives, \"\\t\", false_positives, \"\\n\", false_negatives, \"\\t\", true_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ::  0.555\n",
      "Confusion Matrix :: \n",
      " 52 \t 41 \n",
      " 48 \t 59\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the confusion matrix for the testing dataset.\n",
    "prediction_lst = []\n",
    "for text, label in zip(test_data_input[\"Text\"], test_data_input[\"Label\"]):\n",
    "    prediction_lst.append(predict_sentiment(model, text))\n",
    "\n",
    "true_positives, false_positives, true_negatives, false_negatives = confusion(\n",
    "    torch.Tensor(prediction_lst), torch.Tensor(test_data_input[\"Label\"].to_numpy()))\n",
    "accuracy = (true_positives + true_negatives)/len(prediction_lst)\n",
    "\n",
    "print(\"Accuracy :: \", accuracy)\n",
    "print(\"Confusion Matrix :: \\n\", true_positives, \"\\t\", false_positives, \"\\n\", false_negatives, \"\\t\", true_negatives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
